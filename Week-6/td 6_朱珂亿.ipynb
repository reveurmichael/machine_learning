{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b109dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092f75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"prostate.data\",delimiter=\"\\t\")\n",
    "data2=data.drop([\"Unnamed: 0\",\"train\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708c3a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(data[data.train == \"T\"]['lpsa'])\n",
    "y_test = np.array(data[data.train == \"F\"]['lpsa'])\n",
    "X_train = np.array(data[data.train == \"T\"].drop(['lpsa', 'train', 'Unnamed: 0'], axis=1))\n",
    "X_test = np.array(data[data.train == \"F\"].drop(['lpsa', 'train', 'Unnamed: 0'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3037d",
   "metadata": {},
   "source": [
    "# Best subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2e8d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features\n",
      "1    0.537516\n",
      "2    0.614756\n",
      "3    0.637441\n",
      "4    0.659176\n",
      "5    0.666920\n",
      "6    0.682807\n",
      "7    0.694258\n",
      "8    0.694371\n",
      "Name: R2_score, dtype: float64\n",
      "Best Subset Regression R2_score: 0.694 Best Subset Regression Model: ['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45']\n",
      "Best Subset Regression coefficients: {'Intercept': 0.429, 'lcavol': 0.577, 'lweight': 0.614, 'age': -0.019, 'lbph': 0.145, 'svi': 0.737, 'lcp': -0.206, 'gleason': -0.03, 'pgg45': 0.009}\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['num_features', 'features', 'R2_score'])\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    for subset in itertools.combinations(range(X_train.shape[1]), k):\n",
    "        subset = list(subset)\n",
    "        linreg_model = LinearRegression(normalize=True).fit(X_train[:, subset], y_train)\n",
    "        linreg_prediction = linreg_model.predict(X_train[:, subset])\n",
    "        linreg_score = np.mean(np.abs(r2_score(y_train,linreg_prediction)))\n",
    "        results = results.append(pd.DataFrame([{'num_features': k,\n",
    "                                                'features': subset,\n",
    "                                                'R2_score': linreg_score}]))\n",
    "\n",
    "results = results.sort_values('R2_score',ascending=False).reset_index()\n",
    "results.drop( labels=\"index\" , axis = 1 ,inplace=True)\n",
    "print(results.groupby(\"num_features\")[\"R2_score\"].max())\n",
    "best_subset_model = LinearRegression(normalize=True).fit(X_train[:, results['features'][0]], y_train)\n",
    "best_subset_coefs = dict(\n",
    "    zip(['Intercept'] + data.columns.tolist()[1:-1],\n",
    "        np.round(np.concatenate((best_subset_model.intercept_, best_subset_model.coef_), axis=None), 3))\n",
    ")\n",
    "\n",
    "print('Best Subset Regression R2_score: {}'.format(np.round(results['R2_score'][0], 3)),'Best Subset Regression Model: {}'.format([data2.columns[i] for i in results[\"features\"][0]]))\n",
    "print('Best Subset Regression coefficients:', best_subset_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247b813",
   "metadata": {},
   "source": [
    "# Forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbfd71e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpsa~lcavol\n",
      "lpsa~lweight\n",
      "lpsa~age\n",
      "lpsa~lbph\n",
      "lpsa~svi\n",
      "lpsa~lcp\n",
      "lpsa~gleason\n",
      "lpsa~pgg45\n",
      "lpsa~lcavol+lweight\n",
      "lpsa~lcavol+age\n",
      "lpsa~lcavol+lbph\n",
      "lpsa~lcavol+svi\n",
      "lpsa~lcavol+lcp\n",
      "lpsa~lcavol+gleason\n",
      "lpsa~lcavol+pgg45\n",
      "lpsa~lcavol+lweight+age\n",
      "lpsa~lcavol+lweight+lbph\n",
      "lpsa~lcavol+lweight+svi\n",
      "lpsa~lcavol+lweight+lcp\n",
      "lpsa~lcavol+lweight+gleason\n",
      "lpsa~lcavol+lweight+pgg45\n",
      "lpsa~lcavol+lweight+svi+age\n",
      "lpsa~lcavol+lweight+svi+lbph\n",
      "lpsa~lcavol+lweight+svi+lcp\n",
      "lpsa~lcavol+lweight+svi+gleason\n",
      "lpsa~lcavol+lweight+svi+pgg45\n",
      "forward selection is over!\n",
      "final formula is lpsa~lcavol+lweight+svi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lpsa</td>       <th>  R-squared:         </th> <td>   0.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   54.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 May 2021</td> <th>  Prob (F-statistic):</th> <td>2.44e-20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:30:53</td>     <th>  Log-Likelihood:    </th> <td> -102.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    97</td>      <th>  AIC:               </th> <td>   212.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    93</td>      <th>  BIC:               </th> <td>   222.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.7772</td> <td>    0.623</td> <td>   -1.247</td> <td> 0.215</td> <td>   -2.014</td> <td>    0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lcavol</th>    <td>    0.5259</td> <td>    0.075</td> <td>    7.024</td> <td> 0.000</td> <td>    0.377</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lweight</th>   <td>    0.6618</td> <td>    0.176</td> <td>    3.768</td> <td> 0.000</td> <td>    0.313</td> <td>    1.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>svi</th>       <td>    0.6657</td> <td>    0.207</td> <td>    3.214</td> <td> 0.002</td> <td>    0.254</td> <td>    1.077</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.099</td> <th>  Durbin-Watson:     </th> <td>   1.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.952</td> <th>  Jarque-Bera (JB):  </th> <td>   0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.069</td> <th>  Prob(JB):          </th> <td>   0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.815</td> <th>  Cond. No.          </th> <td>    36.5</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   lpsa   R-squared:                       0.636\n",
       "Model:                            OLS   Adj. R-squared:                  0.624\n",
       "Method:                 Least Squares   F-statistic:                     54.15\n",
       "Date:                Tue, 11 May 2021   Prob (F-statistic):           2.44e-20\n",
       "Time:                        13:30:53   Log-Likelihood:                -102.05\n",
       "No. Observations:                  97   AIC:                             212.1\n",
       "Df Residuals:                      93   BIC:                             222.4\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.7772      0.623     -1.247      0.215      -2.014       0.460\n",
       "lcavol         0.5259      0.075      7.024      0.000       0.377       0.675\n",
       "lweight        0.6618      0.176      3.768      0.000       0.313       1.011\n",
       "svi            0.6657      0.207      3.214      0.002       0.254       1.077\n",
       "==============================================================================\n",
       "Omnibus:                        0.099   Durbin-Watson:                   1.501\n",
       "Prob(Omnibus):                  0.952   Jarque-Bera (JB):                0.215\n",
       "Skew:                          -0.069   Prob(JB):                        0.898\n",
       "Kurtosis:                       2.815   Cond. No.                         36.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_selection(data,target):\n",
    "    variate=data.columns.to_list()\n",
    "    variate.remove(target)  \n",
    "    selected=[]\n",
    "    current_score,best_new_score=float('inf'),float('inf')  \n",
    "    while variate:\n",
    "        bic_with_variate=[]\n",
    "        for feature in variate:  \n",
    "            formula=\"{}~{}\".format(target,\"+\".join(selected+[feature]))\n",
    "            print(formula)\n",
    "            bic=ols(formula=formula,data=data).fit().bic  \n",
    "            bic_with_variate.append((bic,feature))  \n",
    "        bic_with_variate.sort(reverse=True)  \n",
    "        best_new_score,best_feature=bic_with_variate.pop()  \n",
    "        \n",
    "        if current_score >= best_new_score:  \n",
    "            variate.remove(best_feature)  \n",
    "            selected.append(best_feature)  \n",
    "            current_score=best_new_score  \n",
    "        else:\n",
    "            print(\"forward selection is over!\")\n",
    "            break\n",
    "            \n",
    "    formula=\"{}~{}\".format(target,\"+\".join(selected))  \n",
    "    print(\"final formula is {}\".format(formula))\n",
    "    model=ols(formula=formula,data=data).fit()\n",
    "    return(model)\n",
    "\n",
    "fwd = forward_selection(data=data2,target='lpsa')\n",
    "fwd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2771a40c",
   "metadata": {},
   "source": [
    "# Backward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4f00020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_selection(data,target):\n",
    "    variate=data.columns.to_list()\n",
    "    variate.remove(target)  \n",
    "    selected=variate.copy()\n",
    "    current_score,best_new_score=float('inf'),float('inf')  \n",
    "    while variate:\n",
    "        bic_with_variate=[]\n",
    "        for feature in variate: \n",
    "            l = selected.copy()\n",
    "            l.remove(feature)\n",
    "            formula=\"{}~{}\".format(target,\"+\".join(l))\n",
    "            print(formula)\n",
    "            bic=ols(formula=formula,data=data).fit().bic  \n",
    "            bic_with_variate.append((bic,feature))  \n",
    "        bic_with_variate.sort(reverse=True)  \n",
    "        best_new_score,best_feature=bic_with_variate.pop()  \n",
    "        if current_score >= best_new_score:  \n",
    "            variate.remove(best_feature)  \n",
    "            selected.remove(best_feature)  \n",
    "            current_score=best_new_score  \n",
    "        else:\n",
    "            print(\"selection is over\")\n",
    "            break\n",
    "    formula=\"{}~{}\".format(target,\"+\".join(selected))  \n",
    "    print(\"final formula is {}\".format(formula))\n",
    "    model=ols(formula=formula,data=data).fit()\n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6a20846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpsa~lweight+age+lbph+svi+lcp+gleason+pgg45\n",
      "lpsa~lcavol+age+lbph+svi+lcp+gleason+pgg45\n",
      "lpsa~lcavol+lweight+lbph+svi+lcp+gleason+pgg45\n",
      "lpsa~lcavol+lweight+age+svi+lcp+gleason+pgg45\n",
      "lpsa~lcavol+lweight+age+lbph+lcp+gleason+pgg45\n",
      "lpsa~lcavol+lweight+age+lbph+svi+gleason+pgg45\n",
      "lpsa~lcavol+lweight+age+lbph+svi+lcp+pgg45\n",
      "lpsa~lcavol+lweight+age+lbph+svi+lcp+gleason\n",
      "lpsa~lweight+age+lbph+svi+lcp+pgg45\n",
      "lpsa~lcavol+age+lbph+svi+lcp+pgg45\n",
      "lpsa~lcavol+lweight+lbph+svi+lcp+pgg45\n",
      "lpsa~lcavol+lweight+age+svi+lcp+pgg45\n",
      "lpsa~lcavol+lweight+age+lbph+lcp+pgg45\n",
      "lpsa~lcavol+lweight+age+lbph+svi+pgg45\n",
      "lpsa~lcavol+lweight+age+lbph+svi+lcp\n",
      "lpsa~lweight+age+lbph+svi+pgg45\n",
      "lpsa~lcavol+age+lbph+svi+pgg45\n",
      "lpsa~lcavol+lweight+lbph+svi+pgg45\n",
      "lpsa~lcavol+lweight+age+svi+pgg45\n",
      "lpsa~lcavol+lweight+age+lbph+pgg45\n",
      "lpsa~lcavol+lweight+age+lbph+svi\n",
      "lpsa~lweight+age+lbph+svi\n",
      "lpsa~lcavol+age+lbph+svi\n",
      "lpsa~lcavol+lweight+lbph+svi\n",
      "lpsa~lcavol+lweight+age+svi\n",
      "lpsa~lcavol+lweight+age+lbph\n",
      "lpsa~lweight+lbph+svi\n",
      "lpsa~lcavol+lbph+svi\n",
      "lpsa~lcavol+lweight+svi\n",
      "lpsa~lcavol+lweight+lbph\n",
      "lpsa~lweight+svi\n",
      "lpsa~lcavol+svi\n",
      "lpsa~lcavol+lweight\n",
      "selection is over\n",
      "final formula is lpsa~lcavol+lweight+svi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lpsa</td>       <th>  R-squared:         </th> <td>   0.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   54.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 May 2021</td> <th>  Prob (F-statistic):</th> <td>2.44e-20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:31:03</td>     <th>  Log-Likelihood:    </th> <td> -102.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    97</td>      <th>  AIC:               </th> <td>   212.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    93</td>      <th>  BIC:               </th> <td>   222.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.7772</td> <td>    0.623</td> <td>   -1.247</td> <td> 0.215</td> <td>   -2.014</td> <td>    0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lcavol</th>    <td>    0.5259</td> <td>    0.075</td> <td>    7.024</td> <td> 0.000</td> <td>    0.377</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lweight</th>   <td>    0.6618</td> <td>    0.176</td> <td>    3.768</td> <td> 0.000</td> <td>    0.313</td> <td>    1.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>svi</th>       <td>    0.6657</td> <td>    0.207</td> <td>    3.214</td> <td> 0.002</td> <td>    0.254</td> <td>    1.077</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.099</td> <th>  Durbin-Watson:     </th> <td>   1.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.952</td> <th>  Jarque-Bera (JB):  </th> <td>   0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.069</td> <th>  Prob(JB):          </th> <td>   0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.815</td> <th>  Cond. No.          </th> <td>    36.5</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   lpsa   R-squared:                       0.636\n",
       "Model:                            OLS   Adj. R-squared:                  0.624\n",
       "Method:                 Least Squares   F-statistic:                     54.15\n",
       "Date:                Tue, 11 May 2021   Prob (F-statistic):           2.44e-20\n",
       "Time:                        13:31:03   Log-Likelihood:                -102.05\n",
       "No. Observations:                  97   AIC:                             212.1\n",
       "Df Residuals:                      93   BIC:                             222.4\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.7772      0.623     -1.247      0.215      -2.014       0.460\n",
       "lcavol         0.5259      0.075      7.024      0.000       0.377       0.675\n",
       "lweight        0.6618      0.176      3.768      0.000       0.313       1.011\n",
       "svi            0.6657      0.207      3.214      0.002       0.254       1.077\n",
       "==============================================================================\n",
       "Omnibus:                        0.099   Durbin-Watson:                   1.501\n",
       "Prob(Omnibus):                  0.952   Jarque-Bera (JB):                0.215\n",
       "Skew:                          -0.069   Prob(JB):                        0.898\n",
       "Kurtosis:                       2.815   Cond. No.                         36.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwd = backward_selection(data=data2,target=\"lpsa\")\n",
    "bwd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d2a06",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f894ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MAE: 0.517\n",
      "Ridge Regression coefficients: {'Intercept': 0.155, 'lweight': 0.51, 'age': 0.605, 'lbph': -0.016, 'svi': 0.14, 'lcp': 0.692, 'gleason': -0.134}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "ridge_cv = RidgeCV(normalize=True, alphas=np.logspace(-10, 1, 400))\n",
    "ridge_model = ridge_cv.fit(X_train, y_train)\n",
    "ridge_prediction = ridge_model.predict(X_test)\n",
    "ridge_mae = np.mean(np.abs(y_test - ridge_prediction))\n",
    "ridge_coefs = dict(\n",
    "    zip(['Intercept'] + data2.columns.tolist()[1:-2],\n",
    "        np.round(np.concatenate((ridge_model.intercept_, ridge_model.coef_),\n",
    "                                axis=None), 3))\n",
    ")\n",
    "\n",
    "print('Ridge Regression MAE: {}'.format(np.round(ridge_mae, 3)))\n",
    "print('Ridge Regression coefficients:', ridge_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8786940",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f8a8b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO MAE: 0.523\n",
      "LASSO coefficients: {'Intercept': 0.429, 'lweight': 0.577, 'age': 0.614, 'lbph': -0.019, 'svi': 0.145, 'lcp': 0.737, 'gleason': -0.206}\n"
     ]
    }
   ],
   "source": [
    "lasso_cv = LassoCV(normalize=True, alphas=np.logspace(-10, 1, 400))\n",
    "lasso_model = lasso_cv.fit(X_train, y_train)\n",
    "lasso_prediction = lasso_model.predict(X_test)\n",
    "lasso_mae = np.mean(np.abs(y_test - lasso_prediction))\n",
    "lasso_coefs = dict(\n",
    "    zip(['Intercept'] + data2.columns.tolist()[1:-2],\n",
    "        np.round(np.concatenate((lasso_model.intercept_, lasso_model.coef_), axis=None), 3))\n",
    ")\n",
    "\n",
    "print('LASSO MAE: {}'.format(np.round(lasso_mae, 3)))\n",
    "print('LASSO coefficients:', lasso_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14626316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
