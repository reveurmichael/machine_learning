{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [1/10], Loss: 0.2132\n",
      "Accuracy on test set: 96.21%\n",
      "Epoch [2/10], Loss: 0.0882\n",
      "Accuracy on test set: 97.24%\n",
      "Epoch [3/10], Loss: 0.0595\n",
      "Accuracy on test set: 97.69%\n",
      "Epoch [4/10], Loss: 0.0432\n",
      "Accuracy on test set: 98.09%\n",
      "Epoch [5/10], Loss: 0.0331\n",
      "Accuracy on test set: 97.88%\n",
      "Epoch [6/10], Loss: 0.0268\n",
      "Accuracy on test set: 98.16%\n",
      "Epoch [7/10], Loss: 0.0247\n",
      "Accuracy on test set: 98.00%\n",
      "Epoch [8/10], Loss: 0.0193\n",
      "Accuracy on test set: 98.08%\n",
      "Epoch [9/10], Loss: 0.0191\n",
      "Accuracy on test set: 97.84%\n",
      "Epoch [10/10], Loss: 0.0159\n",
      "Accuracy on test set: 97.80%\n",
      "Model saved to mnist_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define transformations for the training and test sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with mean and std of MNIST\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data_gitignore', \n",
    "                                          train=True, \n",
    "                                          transform=transform, \n",
    "                                          download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data_gitignore', \n",
    "                                         train=False, \n",
    "                                         transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=64, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=1000, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 392)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(392, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create the model and move it to the device\n",
    "model = SimpleNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Print statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy on test set: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'mnist_model.pth')\n",
    "print(\"Model saved to mnist_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [1/10], Loss: 0.1338\n",
      "Accuracy on test set: 98.55%\n",
      "Epoch [2/10], Loss: 0.0423\n",
      "Accuracy on test set: 98.76%\n",
      "Epoch [3/10], Loss: 0.0277\n",
      "Accuracy on test set: 99.02%\n",
      "Epoch [4/10], Loss: 0.0198\n",
      "Accuracy on test set: 98.87%\n",
      "Epoch [5/10], Loss: 0.0162\n",
      "Accuracy on test set: 99.31%\n",
      "Epoch [6/10], Loss: 0.0132\n",
      "Accuracy on test set: 99.05%\n",
      "Epoch [7/10], Loss: 0.0093\n",
      "Accuracy on test set: 99.28%\n",
      "Epoch [8/10], Loss: 0.0091\n",
      "Accuracy on test set: 99.20%\n",
      "Epoch [9/10], Loss: 0.0066\n",
      "Accuracy on test set: 98.91%\n",
      "Epoch [10/10], Loss: 0.0080\n",
      "Accuracy on test set: 99.18%\n",
      "Model saved to mnist_cnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define transformations for the training and test sets\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data_gitignore\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data_gitignore\", train=False, transform=transform\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create the model and move it to the device\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"mnist_cnn_model.pth\")\n",
    "print(\"Model saved to mnist_cnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Saved augmented samples to tmp/augmented_samples.png\n",
      "Epoch [1/10], Loss: 0.4934\n",
      "Accuracy on test set: 97.55%\n",
      "Epoch [2/10], Loss: 0.2721\n",
      "Accuracy on test set: 98.63%\n",
      "Epoch [3/10], Loss: 0.2233\n",
      "Accuracy on test set: 98.79%\n",
      "Epoch [4/10], Loss: 0.1981\n",
      "Accuracy on test set: 99.03%\n",
      "Epoch [5/10], Loss: 0.1839\n",
      "Accuracy on test set: 99.25%\n",
      "Epoch [6/10], Loss: 0.1683\n",
      "Accuracy on test set: 99.14%\n",
      "Epoch [7/10], Loss: 0.1575\n",
      "Accuracy on test set: 99.14%\n",
      "Epoch [8/10], Loss: 0.1499\n",
      "Accuracy on test set: 99.35%\n",
      "Epoch [9/10], Loss: 0.1433\n",
      "Accuracy on test set: 99.36%\n",
      "Epoch [10/10], Loss: 0.1414\n",
      "Accuracy on test set: 99.36%\n",
      "Model saved to mnist_augmented_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "\n",
    "# Create a directory to save augmented samples\n",
    "os.makedirs(\"tmp\", exist_ok=True)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Custom PyTorch transform for elastic deformation\n",
    "class ElasticTransform:\n",
    "    def __init__(self, alpha=1.0, sigma=0.1):\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Generate displacement fields\n",
    "        shape = img_np.shape\n",
    "        dx = np.random.rand(*shape) * 2 - 1\n",
    "        dy = np.random.rand(*shape) * 2 - 1\n",
    "\n",
    "        # Gaussian filter the displacement fields\n",
    "        dx = cv2.GaussianBlur(dx, (0, 0), self.sigma) * self.alpha\n",
    "        dy = cv2.GaussianBlur(dy, (0, 0), self.sigma) * self.alpha\n",
    "\n",
    "        # Create meshgrid for mapping coordinates\n",
    "        x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
    "\n",
    "        # Map coordinates\n",
    "        map_x = np.float32(x + dx)\n",
    "        map_y = np.float32(y + dy)\n",
    "\n",
    "        # Apply elastic transform\n",
    "        distorted = cv2.remap(\n",
    "            img_np,\n",
    "            map_x,\n",
    "            map_y,\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            borderMode=cv2.BORDER_REFLECT_101,\n",
    "        )\n",
    "\n",
    "        return Image.fromarray(distorted)\n",
    "\n",
    "\n",
    "# Custom PyTorch transform for salt and pepper noise\n",
    "class SaltPepperNoise:\n",
    "    def __init__(self, prob=0.05):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Add salt noise\n",
    "        salt = np.random.random(img_np.shape) < self.prob\n",
    "        img_np[salt] = 255\n",
    "\n",
    "        # Add pepper noise\n",
    "        pepper = np.random.random(img_np.shape) < self.prob\n",
    "        img_np[pepper] = 0\n",
    "\n",
    "        return Image.fromarray(img_np)\n",
    "\n",
    "\n",
    "# Define advanced transformations for training\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(15),  # Randomly rotate by up to 15 degrees\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random shifts\n",
    "        ElasticTransform(alpha=15.0, sigma=3.0),  # Elastic deformation\n",
    "        SaltPepperNoise(prob=0.01),  # Add salt and pepper noise\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.2, contrast=0.2\n",
    "        ),  # Adjust brightness and contrast\n",
    "        transforms.ToTensor(),  # Convert to tensor first\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        transforms.RandomErasing(\n",
    "            p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0\n",
    "        ),  # Random erasing (must be after ToTensor)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# For test data, we only normalize (no augmentation needed)\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "# Load the MNIST dataset with augmented transforms\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data_gitignore\", train=True, transform=transform_train, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data_gitignore\", train=False, transform=transform_test\n",
    ")\n",
    "\n",
    "\n",
    "# Function to save sample augmented images\n",
    "def save_augmented_samples(num_samples=5):\n",
    "    \"\"\"Save augmented versions of sample images\"\"\"\n",
    "    # Use a separate transform for visualization\n",
    "    vis_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            ElasticTransform(alpha=15.0, sigma=3.0),\n",
    "            SaltPepperNoise(prob=0.01),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create a temporary dataset with visualization transform\n",
    "    vis_dataset = torchvision.datasets.MNIST(\n",
    "        root=\"./data_gitignore\", train=True, transform=vis_transform, download=False\n",
    "    )\n",
    "\n",
    "    # Get some samples\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        img, _ = vis_dataset[i]\n",
    "        samples.append(img)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, img in enumerate(samples):\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(img.squeeze().numpy(), cmap=\"gray\")\n",
    "        plt.title(f\"Sample {i+1}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"tmp/augmented_samples.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved augmented samples to tmp/augmented_samples.png\")\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Save sample augmented images\n",
    "save_augmented_samples()\n",
    "\n",
    "\n",
    "# Use the same CNN model as before\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First block\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Second block\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Third block\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        # Fully connected\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create the model and move it to the device\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"mnist_augmented_model.pth\")\n",
    "print(\"Model saved to mnist_augmented_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
