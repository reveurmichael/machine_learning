# Final Decision 1: Directory Structure & Data Organization Architecture

> **SUPREME AUTHORITY**: This document establishes the definitive directory structure and data organization standards for the Snake Game AI project.

> **See also:** `datasets-folder.md` (Dataset organization), `data-format-decision-guide.md` (Format selection), `unified-path-management-guide.md` (Path standards), `final-decision-10.md` (SUPREME_RULES).

## ðŸŽ¯ **Core Philosophy: Grid-Size Agnostic Multi-Directional Data Ecosystem**

The directory structure implements a sophisticated **multi-directional data ecosystem** where:
- **All tasks generate datasets** during training/evaluation
- **Better models create better datasets** through positive feedback loops
- **Cross-task pollination** improves overall system performance
- **Training produces both models AND datasets simultaneously**

### **SUPREME_RULES Integration**
- **SUPREME_RULE NO.1**: Enforces reading all GOOD_RULES before making directory structure changes to ensure comprehensive understanding
- **SUPREME_RULE NO.2**: Uses precise `final-decision-N.md` format consistently when referencing architectural decisions
- **SUPREME_RULE NO.3**: Enables lightweight common utilities with OOP extensibility while maintaining directory structure patterns through inheritance rather than tight coupling
- **SUPREME_RULE NO.4**: Ensures all markdown files are coherent and aligned through nuclear diffusion infusion process

### **GOOD_RULES Integration**
This document integrates with the **GOOD_RULES** governance system established in `final-decision-10.md`:
- **`datasets-folder.md`**: Authoritative reference for dataset directory organization standards
- **`data-format-decision-guide.md`**: Authoritative reference for format selection criteria
- **`unified-path-management-guide.md`**: Authoritative reference for path management standards
- **`single-source-of-truth.md`**: Ensures no duplication across extension guidelines

## ðŸš« **CRITICAL: NO singleton_utils.py in extensions/common/**

**STOP! READ THIS FIRST**: This project **explicitly FORBIDS**:
- âŒ **singleton_utils.py in extensions/common/utils/**
- âŒ **Any wrapper around ROOT/utils/singleton_utils.py**
- âœ… **USE ROOT/utils/singleton_utils.py** directly when truly needed (it's already generic)

## ðŸŽ¯ **Executive Summary**

This document establishes the **definitive directory structure** for organizing datasets and models in the `./logs/extensions/` folder across all Snake Game AI tasks (1-5). The structure reflects the **multi-directional data ecosystem** where all tasks can both **consume and generate** high-quality datasets and models, strictly following SUPREME_RULES from `final-decision-10.md`.

### **Simple Logging Examples (SUPREME_RULE NO.3)**
All code examples in this document follow **SUPREME_RULE NO.3** by using ROOT/utils/print_utils.py functions rather than complex logging mechanisms:

```python
from utils.print_utils import print_info, print_warning, print_error, print_success

# âœ… CORRECT: Simple logging as per SUPREME_RULE NO.3
def create_dataset_directory(extension_type: str, version: str, grid_size: int):
    """Create dataset directory with proper structure using canonical factory pattern"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    path = f"logs/extensions/datasets/grid-size-{grid_size}/{extension_type}_v{version}_{timestamp}"
    
    os.makedirs(path, exist_ok=True)
    print_info(f"[DatasetManager] Created dataset directory: {path}")  # SUPREME_RULE NO.3
    
    return path

def validate_directory_structure(path: str):
    """Validate directory follows required structure"""
    if not os.path.exists(path):
        print_error(f"[Validator] Directory does not exist: {path}")  # SUPREME_RULE NO.3
        return False
    
    required_files = ["processed_data", "game_logs"]
    for file in required_files:
        if not os.path.exists(os.path.join(path, file)):
            print_error(f"[Validator] Missing required directory: {file}")  # SUPREME_RULE NO.3
            return False
    
    print_success(f"[Validator] Directory structure is valid: {path}")  # SUPREME_RULE NO.3
    return True
```

## ðŸ§  **Key Architectural Insights**

### **1. Multi-Directional Data Flow**
Unlike traditional linear pipelines, our ecosystem recognizes that:
- **All tasks generate datasets** during training/evaluation
- **Better models create better datasets** (positive feedback loop)
- **Cross-task pollination** improves overall system performance
- **Training produces both models AND datasets simultaneously**

### **2. Task Performance Hierarchy**
Expected performance progression (generally):
1. **Heuristics** (Task 1): Baseline, interpretable, deterministic
2. **Supervised** (Task 2): Better than heuristics, fast inference
3. **Reinforcement Learning** (Task 3): **Potentially optimal**, learned through exploration
4. **LLM Fine-tuned** (Task 4): High performance + natural language reasoning
5. **LLM Distilled** (Task 5): Efficient while maintaining quality

### **3. Dataset Quality Features by Source**

| Task Type | Performance | Interpretability | Speed | Special Features |
|-----------|-------------|------------------|-------|------------------|
| **Heuristics** | Baseline | Highest | Fast | Algorithm traces, search paths |
| **Supervised** | Good | Medium | Very Fast | Confidence scores, feature importance |
| **Reinforcement** | Potentially Optimal | Low | Fast | Q-values, policy distributions, exploration data |
| **LLM Fine-tuned** | High | Highest | Slow | Natural language explanations, step-by-step reasoning |
| **LLM Distilled** | Good | High | Medium | Compressed reasoning, efficiency optimized |

## ðŸ“ **Final Directory Structure**

### **Datasets Organization**

```
logs/extensions/datasets/
â””â”€â”€ grid-size-N/
    â”œâ”€â”€ heuristics_v0.03_{timestamp}/          # Task 1 â†’ Task 2 (Traditional ML)
    â”‚   â”œâ”€â”€ bfs/
    â”‚   â”‚   â”œâ”€â”€ game_logs/                     # Original game_N.json, summary.json
    â”‚   â”‚   â””â”€â”€ processed_data/
    â”‚   â”‚       â”œâ”€â”€ tabular_data.csv           # For supervised learning
    â”‚   â”‚       â”œâ”€â”€ sequential_data.npz        # For RNN/LSTM
    â”‚   â”‚       â””â”€â”€ metadata.json
    â”‚   â””â”€â”€ astar/ [same structure]
    â”‚
    â”œâ”€â”€ heuristics_v0.04_{timestamp}/          # Task 1 â†’ Task 4 (LLM Fine-tuning)
    â”‚   â”œâ”€â”€ bfs/
    â”‚   â”‚   â”œâ”€â”€ game_logs/                     # Original game_N.json, summary.json
    â”‚   â”‚   â””â”€â”€ processed_data/
    â”‚   â”‚       â”œâ”€â”€ tabular_data.csv           # Active format for supervised learning
    â”‚   â”‚       â”œâ”€â”€ reasoning_data.jsonl       # LLM fine-tuning format
    â”‚   â”‚       â””â”€â”€ metadata.json
    â”‚   â””â”€â”€ astar/ [same structure]
    â”‚
    â”œâ”€â”€ supervised_v0.02_{timestamp}/          # Task 2 â†’ Others (Improved datasets)
    â”‚   â”œâ”€â”€ mlp_generated/
    â”‚   â”‚   â”œâ”€â”€ game_logs/                     # MLP-generated games
    â”‚   â”‚   â””â”€â”€ processed_data/
    â”‚   â”‚       â”œâ”€â”€ tabular_data.csv           # Higher quality features
    â”‚   â”‚       â”œâ”€â”€ sequential_data.npz        # Better temporal patterns
    â”‚   â”‚       â”œâ”€â”€ confidence_scores.csv      # Model confidence per move
    â”‚   â”‚       â””â”€â”€ metadata.json
    â”‚   â”œâ”€â”€ xgboost_generated/
    â”‚   â””â”€â”€ ensemble_generated/                # Best supervised performance
    â”‚
    â”œâ”€â”€ reinforcement_v0.02_{timestamp}/       # Task 3 â†’ Others (Optimal datasets)
    â”‚   â”œâ”€â”€ dqn_generated/
    â”‚   â”‚   â”œâ”€â”€ game_logs/                     # DQN-generated games
    â”‚   â”‚   â”œâ”€â”€ experience_replay/
    â”‚   â”‚   â”‚   â”œâ”€â”€ transitions.npz            # High-quality state transitions
    â”‚   â”‚   â”‚   â””â”€â”€ episode_data.json
    â”‚   â”‚   â””â”€â”€ processed_data/
    â”‚   â”‚       â”œâ”€â”€ tabular_data.csv           # Optimal policy features
    â”‚   â”‚       â”œâ”€â”€ q_values.npz               # Q-value annotations
    â”‚   â”‚       â”œâ”€â”€ action_probabilities.npz   # Policy distributions
    â”‚   â”‚       â””â”€â”€ metadata.json
    â”‚   â”œâ”€â”€ ppo_generated/
    â”‚   â””â”€â”€ curriculum_generated/              # Curriculum learning datasets
    â”‚
    â”œâ”€â”€ llm_finetune_v0.02_{timestamp}/        # Task 4 â†’ Others (Language-grounded)
    â”‚   â”œâ”€â”€ lora_generated/
    â”‚   â”‚   â”œâ”€â”€ game_logs/                     # LLM-generated games
    â”‚   â”‚   â””â”€â”€ processed_data/
    â”‚   â”‚       â”œâ”€â”€ reasoning_data.jsonl       # Rich explanations
    â”‚   â”‚       â”œâ”€â”€ tabular_data.csv           # Human-interpretable features
    â”‚   â”‚       â”œâ”€â”€ language_features.npz      # Embedding-based features
    â”‚   â”‚       â””â”€â”€ metadata.json
    â”‚   â””â”€â”€ full_model_generated/
    â”‚
    â””â”€â”€ llm_distillation_v0.02_{timestamp}/    # Task 5 â†’ Others (Efficient)
        â”œâ”€â”€ student_generated/
        â”‚   â”œâ”€â”€ game_logs/                     # Distilled model games
        â”‚   â””â”€â”€ processed_data/
        â”‚       â”œâ”€â”€ reasoning_data.jsonl       # Compressed explanations
        â”‚       â”œâ”€â”€ efficiency_metrics.csv     # Speed/quality trade-offs
        â”‚       â””â”€â”€ metadata.json
        â””â”€â”€ ensemble_generated/
```

### **Models Organization (Integrated with Dataset Generation)**

```
logs/extensions/models/
â””â”€â”€ grid-size-N/
    â”œâ”€â”€ supervised_v0.02_{timestamp}/
    â”‚   â”œâ”€â”€ mlp/
    â”‚   â”‚   â”œâ”€â”€ model_artifacts/
    â”‚   â”‚   â”‚   â”œâ”€â”€ model.pth                      # Primary model output
    â”‚   â”‚   â”‚   â”œâ”€â”€ model.onnx                     # Deployment format
    â”‚   â”‚   â”‚   â”œâ”€â”€ config.json                    # Model configuration
    â”‚   â”‚   â”‚   â””â”€â”€ feature_importance.json        # Model interpretability
    â”‚   â”‚   â”œâ”€â”€ training_process/
    â”‚   â”‚   â”‚   â”œâ”€â”€ training_history/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ loss_curves.json
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics_per_epoch.json
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ checkpoints/
    â”‚   â”‚   â”‚   â””â”€â”€ generated_datasets/            # ðŸ”¥ Datasets created during training
    â”‚   â”‚   â”‚       â”œâ”€â”€ validation_games/
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ game_N.json            # Games played during validation
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ summary.json
    â”‚   â”‚   â”‚       â”œâ”€â”€ evaluation_datasets/
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ tabular_data.csv       # Features from evaluation games
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ confidence_scores.csv  # Model confidence per move
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ prediction_analysis.npz
    â”‚   â”‚   â”‚       â””â”€â”€ dataset_metadata.json
    â”‚   â”‚   â””â”€â”€ deployment_ready/
    â”‚   â”‚       â”œâ”€â”€ optimized_model.onnx           # Production-ready
    â”‚   â”‚       â””â”€â”€ inference_config.json
    â”‚   â””â”€â”€ xgboost/ [same structure]
    â”‚
    â”œâ”€â”€ reinforcement_v0.02_{timestamp}/
    â”‚   â”œâ”€â”€ dqn/
    â”‚   â”‚   â”œâ”€â”€ model_artifacts/
    â”‚   â”‚   â”‚   â”œâ”€â”€ policy_network.pth             # Primary RL model
    â”‚   â”‚   â”‚   â”œâ”€â”€ target_network.pth             # Target network
    â”‚   â”‚   â”‚   â”œâ”€â”€ config.json                    # RL hyperparameters
    â”‚   â”‚   â”‚   â””â”€â”€ training_metrics.json
    â”‚   â”‚   â”œâ”€â”€ training_process/
    â”‚   â”‚   â”‚   â”œâ”€â”€ training_history/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ loss_curves.json
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ reward_curves.json
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ exploration_metrics.json
    â”‚   â”‚   â”‚   â””â”€â”€ generated_datasets/            # ðŸ”¥ High-quality RL datasets
    â”‚   â”‚   â”‚       â”œâ”€â”€ optimal_games/
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ game_N.json            # Games with optimal policy
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ summary.json
    â”‚   â”‚   â”‚       â”œâ”€â”€ experience_datasets/
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ transitions.npz        # State-action-reward tuples
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ q_values.npz           # Q-value annotations
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ policy_distributions.npz
    â”‚   â”‚   â”‚       â””â”€â”€ dataset_metadata.json
    â”‚   â”‚   â””â”€â”€ deployment_ready/
    â”‚   â”‚       â”œâ”€â”€ optimized_policy.onnx          # Production-ready
    â”‚   â”‚       â””â”€â”€ inference_config.json
    â”‚   â””â”€â”€ ppo/ [same structure]
    â”‚
    â”œâ”€â”€ llm_finetune_v0.02_{timestamp}/
    â”‚   â”œâ”€â”€ lora/
    â”‚   â”‚   â”œâ”€â”€ model_artifacts/
    â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_model.safetensors      # LoRA adapter weights
    â”‚   â”‚   â”‚   â”œâ”€â”€ base_model_config.json         # Base model configuration
    â”‚   â”‚   â”‚   â”œâ”€â”€ lora_config.json               # LoRA-specific config
    â”‚   â”‚   â”‚   â””â”€â”€ training_metrics.json
    â”‚   â”‚   â”œâ”€â”€ training_process/
    â”‚   â”‚   â”‚   â”œâ”€â”€ training_history/
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ loss_curves.json
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ learning_rate_schedule.json
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ validation_metrics.json
    â”‚   â”‚   â”‚   â””â”€â”€ generated_datasets/            # ðŸ”¥ Language-grounded datasets
    â”‚   â”‚   â”‚       â”œâ”€â”€ reasoning_games/
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ game_N.json            # Games with explanations
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ summary.json
    â”‚   â”‚   â”‚       â”œâ”€â”€ language_datasets/
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ reasoning_data.jsonl   # Rich explanations
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ language_features.npz  # Embedding-based features
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ explanation_quality.csv
    â”‚   â”‚   â”‚       â””â”€â”€ dataset_metadata.json
    â”‚   â”‚   â””â”€â”€ deployment_ready/
    â”‚   â”‚       â”œâ”€â”€ merged_model.safetensors        # Production-ready
    â”‚   â”‚       â””â”€â”€ inference_config.json
    â”‚   â””â”€â”€ full_model/ [same structure]
    â”‚
    â””â”€â”€ llm_distillation_v0.02_{timestamp}/
        â”œâ”€â”€ student/
        â”‚   â”œâ”€â”€ model_artifacts/
        â”‚   â”‚   â”œâ”€â”€ student_model.pth               # Distilled student model
        â”‚   â”‚   â”œâ”€â”€ teacher_model.pth               # Reference teacher model
        â”‚   â”‚   â”œâ”€â”€ config.json                     # Distillation config
        â”‚   â”‚   â””â”€â”€ efficiency_metrics.json
        â”‚   â”œâ”€â”€ training_process/
        â”‚   â”‚   â”œâ”€â”€ training_history/
        â”‚   â”‚   â”‚   â”œâ”€â”€ distillation_loss.json
        â”‚   â”‚   â”‚   â”œâ”€â”€ efficiency_curves.json
        â”‚   â”‚   â”‚   â””â”€â”€ quality_metrics.json
        â”‚   â”‚   â””â”€â”€ generated_datasets/            # ðŸ”¥ Efficient datasets
        â”‚   â”‚       â”œâ”€â”€ efficient_games/
        â”‚   â”‚       â”‚   â”œâ”€â”€ game_N.json            # Games with efficiency focus
        â”‚   â”‚       â”‚   â””â”€â”€ summary.json
        â”‚   â”‚       â”œâ”€â”€ efficiency_datasets/
        â”‚   â”‚       â”‚   â”œâ”€â”€ reasoning_data.jsonl   # Compressed explanations
        â”‚   â”‚       â”‚   â”œâ”€â”€ efficiency_metrics.csv # Speed/quality trade-offs
        â”‚   â”‚       â”‚   â””â”€â”€ compression_analysis.npz
        â”‚   â”‚       â””â”€â”€ dataset_metadata.json
        â”‚   â””â”€â”€ deployment_ready/
        â”‚       â”œâ”€â”€ optimized_student.onnx          # Production-ready
        â”‚       â””â”€â”€ inference_config.json
        â””â”€â”€ ensemble/ [same structure]
```

### **Extension Guidelines**
This directory structure supports:
- All extension types (heuristics, supervised, reinforcement, LLM)
- All grid sizes (8x8, 10x10, 12x12, 16x16, 20x20)
- All data formats (CSV, NPZ, JSONL)
- Cross-extension data sharing and reuse

---

**This directory structure ensures consistent, scalable, and educational data organization across all Snake Game AI extensions while enabling the multi-directional data ecosystem that drives continuous improvement.**

> **SUPREME_RULES COMPLIANCE**: This document strictly follows the SUPREME_RULES established in `final-decision-10.md`, ensuring coherence, educational value, and architectural integrity across the entire project.
