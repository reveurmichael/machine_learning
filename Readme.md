
## Reading materials:

[Why the mean of residuals in linear regression is always zero](https://thestatsgeek.com/2020/03/23/the-mean-of-residuals-in-linear-regression-is-always-zero/)

[The real reason you use MSE and cross-entropy loss functions](https://www.expunctis.com/2019/01/27/Loss-functions.html)

[Minimizing relative error (or mean square error) and maximizing likelihood
](https://stats.stackexchange.com/questions/79188/minimizing-relative-error-or-mean-square-error-and-maximizing-likelihood)

[MSE as Maximum Likelihood](https://www.jessicayung.com/mse-as-maximum-likelihood/)

[Three Justifications for OLS](https://web.stanford.edu/class/stats253/lectures/lect2.pdf)

[Can we use MSE for logistic regression?](https://medium.com/analytics-vidhya/understanding-the-loss-function-of-logistic-regression-ac1eec2838ce)

[Why Using Mean Squared Error(MSE) Cost Function for Binary Classification is a Bad Idea?
](https://towardsdatascience.com/why-using-mean-squared-error-mse-cost-function-for-binary-classification-is-a-bad-idea-933089e90df7)


## 上课讲了但是发过来的 slides 上没有更新:

[Rand index](https://en.wikipedia.org/wiki/Rand_index)









